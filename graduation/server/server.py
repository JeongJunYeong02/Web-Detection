# server.py (SSIM ìµœì¢… ìˆ˜ì •ë³¸: win_size ë° channel_axis ëª…ì‹œ)

from flask import Flask, request, jsonify
from flask_cors import CORS
from web_forgery_detector import WebForgeryDetector 
import traceback
import json
import os
import base64
import io
from PIL import Image

# ------------------ Flask ì´ˆê¸°í™” ------------------
app = Flask(__name__)
CORS(app)

# ------------------ ê²½ë¡œ ì„¤ì • ------------------
base_dir = os.path.dirname(os.path.abspath(__file__))

# ------------------ 1. ì›¹ ìœ„ë³€ì¡° íƒì§€ê¸° ------------------
print("íƒì§€ê¸° ì´ˆê¸°í™” ì¤‘...")
try:
    detector = WebForgeryDetector(
        whitelist_csv_path=os.path.join(base_dir, "top10.csv"),
        baseline_html_path=os.path.join(base_dir, "normal.html"),
        baseline_url="http://localhost:8000/normal.html#"
    )
    print("âœ… íƒì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ!")
except Exception as e:
    print(f"âŒ íƒì§€ê¸° ë¡œë“œ ì‹¤íŒ¨: {e}")
    detector = None

@app.route('/check_current_page', methods=['POST'])
def check_current_page():
    if detector is None:
        return jsonify({"error": "WebForgeryDetectorê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 500
    try:
        data = request.json
        print(f"\n[ì›¹ ë¶„ì„] URL: {data.get('url', 'Unknown')}")
        results = detector.analyze_with_baseline(data.get('html', ''), data.get('url', ''))
        print(f"ì›¹ ë¶„ì„ ì™„ë£Œ âœ… ìœ„í—˜ë„: {results['risk_assessment']['risk_score']}ì ")
        return jsonify(results)
    except Exception as e:
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

# ------------------ 2. ì´ë¯¸ì§€ ìœ ì‚¬ë„ ë¶„ì„ ------------------
import torch
import torchvision.transforms as T
import torch.nn as nn
import numpy as np
from skimage.metrics import structural_similarity as ssim

MODEL_PATH = os.path.join(base_dir, "autoencoder_trained_multi.pth")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class AutoEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, 3, stride=2, padding=1), nn.ReLU(),
            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),
            nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),
            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),
            nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1, output_padding=1), nn.Sigmoid()
        )
    def forward(self, x):
        return self.decoder(self.encoder(x))

try:
    print("ðŸ”¹ AutoEncoder ë¡œë“œ ì¤‘...")
    model = AutoEncoder().to(device)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    model.eval()
    print("âœ… AutoEncoder ë¡œë“œ ì™„ë£Œ!")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    model = None

transform = T.Compose([T.Resize((256, 256)), T.ToTensor()])

def compare_images_v2(img1_pil, img2_pil):
    """ â˜… [ìˆ˜ì •] ì—ëŸ¬ ë©”ì‹œì§€ ìš”êµ¬ì‚¬í•­ ë°˜ì˜ """
    img1_resized = img1_pil.resize((256, 256)).convert("RGB")
    img2_resized = img2_pil.resize((256, 256)).convert("RGB")
    
    img1_np = np.array(img1_resized)
    img2_np = np.array(img2_resized)
    
    # â˜…â˜…â˜… [ìˆ˜ì •] ì—ëŸ¬ ë©”ì‹œì§€ê°€ ìš”êµ¬í•œ íŒŒë¼ë¯¸í„°ë¥¼ ëª¨ë‘ ì¶”ê°€í•©ë‹ˆë‹¤. â˜…â˜…â˜…
    score = ssim(img1_np, img2_np, 
                 win_size=7,          # 1. ìœˆë„ìš° í¬ê¸° ëª…ì‹œ
                 channel_axis=-1,     # 2. ì»¬ëŸ¬ ì±„ë„ ì¶• ëª…ì‹œ (RGBê°€ ë§ˆì§€ë§‰ ì¶•)
                 data_range=255       # 3. ë°ì´í„° ë²”ìœ„ ëª…ì‹œ
                )
    
    return max(0, min(100, score * 100)) # 0~100ì  ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜

def load_image_from_base64(data_url):
    header, encoded = data_url.split(',', 1)
    return Image.open(io.BytesIO(base64.b64decode(encoded))).convert("RGB")

def encode_image(img_pil):
    img_tensor = transform(img_pil).unsqueeze(0).to(device)
    with torch.no_grad():
        encoded = model.encoder(img_tensor)
    return encoded.squeeze().cpu()

@app.route('/analyze', methods=['POST'])
def analyze_images():
    if model is None: return jsonify({"error": "AI ëª¨ë¸ ì—†ìŒ"}), 500
    try:
        data = request.json
        img1_path = os.path.join(base_dir, data.get("img1_path"))
        img2_data = data.get("img2_data")

        print(f"\n[ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­] ê¸°ì¤€: {os.path.basename(img1_path)} vs ìŠ¤ëƒ…ìƒ·")

        if not os.path.exists(img1_path): return jsonify({"error": "ê¸°ì¤€ ì´ë¯¸ì§€ ì—†ìŒ"}), 404
        if not img2_data: return jsonify({"error": "ìŠ¤ëƒ…ìƒ· ë°ì´í„° ì—†ìŒ"}), 400

        img1_pil = Image.open(img1_path).convert("RGB")
        img2_pil = load_image_from_base64(img2_data)

        vec1 = encode_image(img1_pil).flatten()
        vec2 = encode_image(img2_pil).flatten()
        cosine_score = torch.nn.functional.cosine_similarity(vec1, vec2, dim=0).item()

        structural_score = compare_images_v2(img1_pil, img2_pil)

        final_score = (cosine_score * 50) + (structural_score * 0.5)
        
        print(f"ðŸ“Š ì½”ì‚¬ì¸ ì ìˆ˜: {cosine_score:.4f} -> í™˜ì‚°: {cosine_score * 50:.2f}/50")
        print(f"ðŸ“¸ êµ¬ì¡°(SSIM): {structural_score:.2f} -> í™˜ì‚°: {structural_score * 0.5:.2f}/50")
        print(f"âœ… ìµœì¢… ê²°í•©: {final_score:.2f}/100")

        return jsonify({
            "cosine": cosine_score * 100,
            "structural": structural_score,
            "final": final_score
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

# ------------------ ì‹¤í–‰ ------------------
if __name__ == '__main__':
    app.run(host='127.0.0.1', port=5050, debug=True)